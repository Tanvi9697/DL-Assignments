{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt1srzs7AfyP",
        "outputId": "7172cf5c-b471-4390-a1dd-152f060139c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import os # Import for file handling\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "ebj4PBBQ-oUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DOWNLOAD THESE NLTK RESOURCES**"
      ],
      "metadata": {
        "id": "ZGtnAL68FG3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLKHIOrR--II",
        "outputId": "266a61bd-97e6-47ed-a061-7970389ded08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model Parameters ---\n",
        "TEXT_FILE_PATH = '/content/drive/MyDrive/colab datasets/LP4_datasets/cbow.txt' # <-- CHANGE THIS if your file name is different\n",
        "WINDOW_SIZE = 2                # Number of context words to consider on each side\n",
        "EMBEDDING_DIM = 100            # Dimension of the final word vector\n",
        "EPOCHS = 50                    # Number of training epochs (Increase for better results)"
      ],
      "metadata": {
        "id": "s5767jbi_oP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **a. Data preparation**"
      ],
      "metadata": {
        "id": "d96WMjdNFXNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(file_path):\n",
        "\n",
        "    # 1. Read the text from the file\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    # 2. Clean and Tokenize\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text) # Remove punctuation and numbers\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # 3. Build Vocabulary\n",
        "    vocabulary = sorted(list(set(tokens)))\n",
        "\n",
        "    # Create mappings\n",
        "    word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "    index_to_word = {i: word for i, word in enumerate(vocabulary)}\n",
        "\n",
        "    VOCAB_SIZE = len(vocabulary)\n",
        "    print(f\"Total vocabulary size: {VOCAB_SIZE} unique words.\")\n",
        "\n",
        "    return tokens, VOCAB_SIZE, word_to_index, index_to_word"
      ],
      "metadata": {
        "id": "3qDgNBa6A-4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and process the data\n",
        "tokens, VOCAB_SIZE, word_to_index, index_to_word = preprocess_text(TEXT_FILE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOqorI5gBGbO",
        "outputId": "53071282-3cb1-420b-9137-da3aa2f4fbf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total vocabulary size: 92 unique words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **b. Generate training data (Context-Target Pairs)**"
      ],
      "metadata": {
        "id": "i6M2L_dpFgLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_cbow_data(tokens, word_to_index, vocab_size, window_size):\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for i, target_word in enumerate(tokens):\n",
        "        target_index = word_to_index[target_word]\n",
        "        context_indices = []\n",
        "\n",
        "        # Collect context words within the window\n",
        "        for j in range(1, window_size + 1):\n",
        "            if i - j >= 0:\n",
        "                context_indices.append(word_to_index[tokens[i - j]])\n",
        "            if i + j < len(tokens):\n",
        "                context_indices.append(word_to_index[tokens[i + j]])\n",
        "\n",
        "        if context_indices:\n",
        "            data.append((context_indices, target_index))\n",
        "\n",
        "    # Convert the context indices into a summed one-hot vector for simplicity in Keras\n",
        "    X_cbow = np.zeros((len(data), vocab_size), dtype='float32')\n",
        "    Y_cbow = np.zeros((len(data), vocab_size), dtype='float32')\n",
        "\n",
        "    for row_idx, (context_indices, target_index) in enumerate(data):\n",
        "        # Create summed one-hot vector for context (X)\n",
        "        for index in context_indices:\n",
        "            X_cbow[row_idx, index] += 1\n",
        "\n",
        "        # Create one-hot vector for target (Y)\n",
        "        Y_cbow[row_idx, target_index] = 1\n",
        "\n",
        "    print(f\"Total training samples generated: {len(data)}\")\n",
        "    print(f\"Final Input Shape (X): {X_cbow.shape}\")\n",
        "    print(f\"Final Output Shape (Y): {Y_cbow.shape}\")\n",
        "\n",
        "    return X_cbow, Y_cbow"
      ],
      "metadata": {
        "id": "m3vdS8gLB1lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the data\n",
        "\n",
        "X_cbow, Y_cbow = generate_cbow_data(tokens, word_to_index, VOCAB_SIZE, WINDOW_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnFOTD7NB5Fx",
        "outputId": "b423660b-98c3-4182-aac5-88ea46f1fc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples generated: 177\n",
            "Final Input Shape (X): (177, 92)\n",
            "Final Output Shape (Y): (177, 92)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# c. **Create & Train the Model**"
      ],
      "metadata": {
        "id": "l1fk-OCYFpAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDefining CBOW Model Architecture...\")\n",
        "model = Sequential([\n",
        "    # Input Layer: One-hot encoded context vector (size: VOCAB_SIZE)\n",
        "    # This Dense layer is the projection layer (it learns the embeddings)\n",
        "    Dense(EMBEDDING_DIM, activation='linear', input_shape=(VOCAB_SIZE,), name='Embedding_Projection'),\n",
        "\n",
        "    # Output Layer: Predicts the target word (size: VOCAB_SIZE)\n",
        "    Dense(VOCAB_SIZE, activation='softmax', name='Output_Softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4sszTDACPRS",
        "outputId": "d085a41c-55e2-402d-86d5-cd88d2a2a95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Defining CBOW Model Architecture...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.01),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "pefBuUwZCRiM",
        "outputId": "18e5edb0-8858-4f94-c06e-eb4e3664dae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Embedding_Projection (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m9,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output_Softmax (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m92\u001b[0m)             │         \u001b[38;5;34m9,292\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Embedding_Projection (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output_Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,292</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,592\u001b[0m (72.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,592</span> (72.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,592\u001b[0m (72.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,592</span> (72.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "print(f\"\\nStarting CBOW model training for {EPOCHS} epochs...\")\n",
        "model.fit(\n",
        "    X_cbow, Y_cbow,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")\n",
        "print(\"CBOW model training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "T1m9P5T0CTv_",
        "outputId": "bef8fc3f-2a81-4409-8fd0-48149d726bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting CBOW model training for 50 epochs...\n",
            "Epoch 1/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0249 - loss: 4.5111   \n",
            "Epoch 2/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3452 - loss: 3.7000 \n",
            "Epoch 3/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4037 - loss: 2.9771 \n",
            "Epoch 4/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5222 - loss: 2.2904 \n",
            "Epoch 5/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7173 - loss: 1.6021 \n",
            "Epoch 6/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8359 - loss: 1.0776 \n",
            "Epoch 7/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9219 - loss: 0.6750 \n",
            "Epoch 8/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9721 - loss: 0.4225 \n",
            "Epoch 9/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.3005 \n",
            "Epoch 10/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9913 - loss: 0.1997 \n",
            "Epoch 11/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.1571 \n",
            "Epoch 12/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9901 - loss: 0.1150 \n",
            "Epoch 13/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.1051 \n",
            "Epoch 14/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0797 \n",
            "Epoch 15/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0691 \n",
            "Epoch 16/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0565 \n",
            "Epoch 17/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0528 \n",
            "Epoch 18/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0504 \n",
            "Epoch 19/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0465 \n",
            "Epoch 20/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0354 \n",
            "Epoch 21/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0391 \n",
            "Epoch 22/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0490 \n",
            "Epoch 23/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.0306\n",
            "Epoch 24/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0264\n",
            "Epoch 25/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0258\n",
            "Epoch 26/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.0395\n",
            "Epoch 27/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9901 - loss: 0.0282 \n",
            "Epoch 28/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.0237 \n",
            "Epoch 29/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0228 \n",
            "Epoch 30/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0250\n",
            "Epoch 31/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.0248 \n",
            "Epoch 32/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0191\n",
            "Epoch 33/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0222\n",
            "Epoch 34/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9901 - loss: 0.0216 \n",
            "Epoch 35/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.0252\n",
            "Epoch 36/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9949 - loss: 0.0246\n",
            "Epoch 37/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.0213\n",
            "Epoch 38/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0133\n",
            "Epoch 39/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0162\n",
            "Epoch 40/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9949 - loss: 0.0183 \n",
            "Epoch 41/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0232 \n",
            "Epoch 42/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9857 - loss: 0.0239\n",
            "Epoch 43/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0158\n",
            "Epoch 44/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0186\n",
            "Epoch 45/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9857 - loss: 0.0286\n",
            "Epoch 46/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.0436\n",
            "Epoch 47/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0089 \n",
            "Epoch 48/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0168 \n",
            "Epoch 49/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9882 - loss: 0.0266\n",
            "Epoch 50/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.0148\n",
            "CBOW model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **d. Output (Extracting and Analysing Embeddings)**"
      ],
      "metadata": {
        "id": "xX0SJDDLFzZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The word embeddings are the weights of the 'Embedding_Projection' layer.\n",
        "word_embeddings = model.get_layer('Embedding_Projection').get_weights()[0]\n",
        "\n",
        "print(f\"Extracted Embedding Matrix Shape: {word_embeddings.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slMbVv-uC2Tw",
        "outputId": "315e9b57-ff3d-4858-b717-19916ccc8e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Embedding Matrix Shape: (92, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJj_YxnN-NR4",
        "outputId": "3e612a2f-d1d4-4b2c-9f75-4890e172b3ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Embedding vector for 'learning' (First 5 dimensions):\n",
            "[ 0.24829732  0.2840119  -0.50046915  0.18894312  0.3368835 ] ...\n"
          ]
        }
      ],
      "source": [
        "# Example: Get the embedding vector for the word 'learning' (or any other word from the document)\n",
        "\n",
        "word_of_interest = 'learning'\n",
        "if word_of_interest in word_to_index:\n",
        "    idx = word_to_index[word_of_interest]\n",
        "    vector = word_embeddings[idx]\n",
        "\n",
        "    print(f\"\\nEmbedding vector for '{word_of_interest}' (First 5 dimensions):\")\n",
        "    # Display the first 5 dimensions of the vector\n",
        "    print(vector[:5], '...')\n",
        "\n",
        "    # The resulting vector is the semantic representation of the word.\n",
        "else:\n",
        "    print(f\"Word '{word_of_interest}' not found in vocabulary.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bccac655"
      },
      "source": [
        "def predict_target_word(context_words, model, word_to_index, index_to_word, vocab_size, window_size):\n",
        "\n",
        "    # 1. Convert context words to indices and then to a summed one-hot vector\n",
        "    context_vector = np.zeros((1, vocab_size), dtype='float32')\n",
        "    for word in context_words:\n",
        "        if word in word_to_index:\n",
        "            context_vector[0, word_to_index[word]] += 1\n",
        "        else:\n",
        "            print(f\"Warning: Context word '{word}' not in vocabulary. Skipping.\")\n",
        "\n",
        "    # 2. Use the model to predict the probability distribution of the target word\n",
        "    predictions = model.predict(context_vector, verbose=0)[0] # Get the first (and only) sample's predictions\n",
        "\n",
        "    # 3. Get the index of the word with the highest probability\n",
        "    predicted_index = np.argmax(predictions)\n",
        "\n",
        "    # 4. Convert the index back to a word\n",
        "    predicted_word = index_to_word[predicted_index]\n",
        "\n",
        "    # You can also get the probability of the predicted word\n",
        "    predicted_probability = predictions[predicted_index]\n",
        "\n",
        "    return predicted_word, predicted_probability"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "\n",
        "example_context = ['shorter', 'incubation', 'period'] # Example: Predict the word between 'making' and 'important'\n",
        "\n",
        "predicted_word, probability = predict_target_word(\n",
        "    example_context, model, word_to_index, index_to_word, VOCAB_SIZE, WINDOW_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "qV1mCDj1EbvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nGiven the context words: {example_context}\")\n",
        "print(f\"Predicted target word: '{predicted_word}' with probability {probability:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEBR8AA0Egqm",
        "outputId": "c7b1db31-a345-4e96-e9f2-93220a218e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Given the context words: ['shorter', 'incubation', 'period']\n",
            "Predicted target word: 'median' with probability 0.9204\n"
          ]
        }
      ]
    }
  ]
}